{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7675656-d17a-4c37-a681-8a0c95695006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a9b6fd1-a548-47a1-82c1-bc02f53a2279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalch</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>heart_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145.00</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.300</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>160.00</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.00</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.00</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>127.00</td>\n",
       "      <td>333.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>154.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143.06</td>\n",
       "      <td>139.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.042</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>122.00</td>\n",
       "      <td>223.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>150.81</td>\n",
       "      <td>385.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110.63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.181</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>254.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>919 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex   cp  trestbps   chol  fbs  restecg  thalch  exang  oldpeak  \\\n",
       "0     63  0.0  0.0    145.00  233.0  1.0      2.0  150.00    NaN    2.300   \n",
       "1     67  0.0  3.0    160.00  286.0  0.0      2.0  108.00    1.0    1.500   \n",
       "2     67  0.0  3.0    120.00  229.0  0.0      2.0  129.00    1.0    2.600   \n",
       "3     37  0.0  2.0    130.00  250.0  0.0      0.0  187.00    0.0    3.500   \n",
       "4     41  1.0  1.0    130.00  204.0  0.0      2.0  172.00    0.0    1.400   \n",
       "..   ...  ...  ...       ...    ...  ...      ...     ...    ...      ...   \n",
       "914   54  1.0  3.0    127.00  333.0  1.0      1.0  154.00    0.0    0.000   \n",
       "915   62  0.0  0.0    143.06  139.0  NaN      1.0  119.94    1.0    2.042   \n",
       "916   55  NaN  3.0    122.00  223.0  1.0      1.0  100.00    0.0    0.000   \n",
       "917   58  0.0  3.0    150.81  385.0  1.0      2.0  110.63    1.0    2.181   \n",
       "918   62  0.0  1.0    120.00  254.0  0.0      2.0   93.00    1.0    0.000   \n",
       "\n",
       "     slope   ca  thal  heart_status  \n",
       "0      2.0  0.0     1           0.0  \n",
       "1      1.0  3.0     0           2.0  \n",
       "2      1.0  2.0     2           1.0  \n",
       "3      2.0  0.0     0           0.0  \n",
       "4      0.0  0.0     0           0.0  \n",
       "..     ...  ...   ...           ...  \n",
       "914    1.0  0.0     0           1.0  \n",
       "915    1.0  NaN     2           0.0  \n",
       "916    1.0  1.0     1           2.0  \n",
       "917    1.0  0.0     2           NaN  \n",
       "918    1.0  1.0     2           1.0  \n",
       "\n",
       "[919 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and Inspect the Data (replace with actual path)\n",
    "data = pd.read_csv('C:/Users/CAMARA NADEGE/Desktop/biomedical data analysis/heart_disease_1.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94463a2f-d924-4715-ac9f-4181aa1324da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validated Model Accuracy: 0.7000\n",
      "\n",
      "Patient Predictions:\n",
      "            age  sex  cp  trestbps    chol  fbs  restecg  thalch  exang  \\\n",
      "Patient CL   64    1   3    110.00  211.00    0        0  144.00      1   \n",
      "Patient CK   63    1   3    140.00  463.00    0        2  104.00      0   \n",
      "Patient CT   54    1   0     98.00  306.00    1        0  128.00      1   \n",
      "Patient CJ   39    0   1    120.00  260.00    0        1  202.00      0   \n",
      "Patient CD   77    1   1    356.00  145.00    0        1  143.00      0   \n",
      "Patient CZ   45    0   3    102.00  333.00    0        2  117.00      1   \n",
      "Patient CA   22    1   3    108.00  194.00    1        0  136.00      0   \n",
      "Patient CF   51    0   2    190.00    0.00    0        0   92.00      0   \n",
      "Patient CV   48    0   2    140.00  141.15    0        1   93.34      1   \n",
      "Patient CM   56    0   1    135.82  142.00    1        0  226.17      1   \n",
      "\n",
      "            oldpeak  slope  ca  thal  predicted_heart_status  \n",
      "Patient CL    1.800      1   0     2                       0  \n",
      "Patient CK    4.000      1   3     2                       1  \n",
      "Patient CT    0.000      1   1     0                       0  \n",
      "Patient CJ    0.900      2   0     2                       0  \n",
      "Patient CD    0.000      1   0     2                       0  \n",
      "Patient CZ    0.000      1   3     1                       1  \n",
      "Patient CA    1.900      1   3     0                       0  \n",
      "Patient CF    2.400      1   2     0                       0  \n",
      "Patient CV    1.500      1   3     2                       0  \n",
      "Patient CM    2.545      1   2     2                       1  \n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Rearranged patient data\n",
    "patients = {\n",
    "    \"Patient CL\": [64, 1, 3, 110, 211, 0, 0, 144, 1, 1.8, 1, 0, 2],\n",
    "    \"Patient CK\": [63, 1, 3, 140, 463, 0, 2, 104, 0, 4, 1, 3, 2],\n",
    "    \"Patient CT\": [54, 1, 0, 98, 306, 1, 0, 128, 1, 0, 1, 1, 0],\n",
    "    \"Patient CJ\": [39, 0, 1, 120, 260, 0, 1, 202, 0, 0.9, 2, 0, 2],\n",
    "    \"Patient CD\": [77, 1, 1, 356, 145, 0, 1, 143, 0, 0, 1, 0, 2],\n",
    "    \"Patient CZ\": [45, 0, 3, 102, 333, 0, 2, 117, 1, 0, 1, 3, 1],\n",
    "    \"Patient CA\": [22, 1, 3, 108, 194, 1, 0, 136, 0, 1.9, 1, 3, 0],\n",
    "    \"Patient CF\": [51, 0, 2, 190, 0, 0, 0, 92, 0, 2.4, 1, 2, 0],\n",
    "    \"Patient CV\": [48, 0, 2, 140, 141.15, 0, 1, 93.34, 1, 1.5, 1, 3, 2],\n",
    "    \"Patient CM\": [56, 0, 1, 135.82, 142, 1, 0, 226.17, 1, 2.545, 1, 2, 2]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the patient data\n",
    "patient_df = pd.DataFrame.from_dict(patients, orient='index', columns=[\n",
    "    'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalch', \n",
    "    'exang', 'oldpeak', 'slope', 'ca', 'thal'\n",
    "])\n",
    "\n",
    "# Generate random binary 'heart_status' for demonstration purposes\n",
    "np.random.seed(42)\n",
    "patient_df['heart_status'] = np.random.randint(0, 2, size=patient_df.shape[0])\n",
    "\n",
    "# Split the data into features and target\n",
    "X = patient_df.drop(columns=['heart_status'])\n",
    "y = patient_df['heart_status']\n",
    "\n",
    "# Apply SMOTE to the training set with k_neighbors=1\n",
    "smote = SMOTE(random_state=42, k_neighbors=1)\n",
    "X_smote, y_smote = smote.fit_resample(X, y)\n",
    "\n",
    "# Check for NaN/Inf after SMOTE\n",
    "X_smote = np.nan_to_num(X_smote, nan=0, posinf=0, neginf=0)\n",
    "\n",
    "# Polynomial Feature Expansion to include interaction terms\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_poly = poly.fit_transform(X_smote)\n",
    "\n",
    "# Check for NaN/Inf after Polynomial Features\n",
    "X_poly = np.nan_to_num(X_poly, nan=0, posinf=0, neginf=0)\n",
    "\n",
    "# Scale the features after SMOTE\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_poly)\n",
    "\n",
    "# Check for NaN/Inf after Scaling\n",
    "X_scaled = np.nan_to_num(X_scaled, nan=0, posinf=0, neginf=0)\n",
    "\n",
    "# Define base models with hyperparameter tuning\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_params = {'n_estimators': [200, 300, 400], 'max_depth': [6, 8, 10], 'min_samples_split': [2, 5]}\n",
    "rf_search = GridSearchCV(rf_model, rf_params, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "rf_search.fit(X_scaled, y_smote)\n",
    "\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_params = {'n_estimators': [200, 300], 'max_depth': [3, 4, 5], 'learning_rate': [0.01, 0.05, 0.1]}\n",
    "gb_search = GridSearchCV(gb_model, gb_params, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "gb_search.fit(X_scaled, y_smote)\n",
    "\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=500, solver='liblinear')\n",
    "\n",
    "# Adding Decision Tree as a new model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_params = {'max_depth': [4, 6, 8], 'min_samples_split': [2, 5]}\n",
    "dt_search = GridSearchCV(dt_model, dt_params, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "dt_search.fit(X_scaled, y_smote)\n",
    "\n",
    "# Ensemble Model using Voting Classifier with hard voting for potentially higher accuracy\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_search.best_estimator_), \n",
    "        ('gb', gb_search.best_estimator_), \n",
    "        ('lr', lr_model),\n",
    "        ('dt', dt_search.best_estimator_)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "# Train the ensemble model on the SMOTE-enhanced data\n",
    "ensemble_model.fit(X_scaled, y_smote)\n",
    "\n",
    "# Use cross-validation to evaluate model accuracy\n",
    "cv_scores = cross_val_score(ensemble_model, X_scaled, y_smote, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-Validated Model Accuracy: {cv_scores.mean():.4f}\")\n",
    "\n",
    "# Prepare test data for prediction (ensure no feature names in input to `transform`)\n",
    "X_test_poly = poly.transform(X.values)\n",
    "X_test_scaled = scaler.transform(X_test_poly)\n",
    "X_test_scaled = np.nan_to_num(X_test_scaled, nan=0, posinf=0, neginf=0)  # Handle NaNs/Infs in test data\n",
    "\n",
    "predictions = ensemble_model.predict(X_test_scaled)\n",
    "\n",
    "# Display predictions\n",
    "patient_df['predicted_heart_status'] = predictions\n",
    "print(\"\\nPatient Predictions:\")\n",
    "print(patient_df[['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalch', \n",
    "                  'exang', 'oldpeak', 'slope', 'ca', 'thal', 'predicted_heart_status']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cfaf4f-516a-4262-be9f-71f4776ad742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
